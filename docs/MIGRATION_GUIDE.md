# ğŸ”„ GUIA DE MIGRAÃ‡ÃƒO - CPU â†’ GPU

## ğŸ“‹ SITUAÃ‡ÃƒO ATUAL

- â³ Treinamento no PC atual (CPU) estÃ¡ levando 4+ horas
- ğŸ® GPU (GTX 1060 3GB) estÃ¡ em outro PC
- ğŸ”„ Precisamos migrar o projeto para o PC com GPU

---

## ğŸš€ PASSO A PASSO - MIGRAÃ‡ÃƒO

### **1ï¸âƒ£ Preparar repositÃ³rio (PC atual)**

```bash
# Navegar para a raiz do projeto
cd "C:\projetos\Fila de IdÃ©ias\TradeSigns\emDevComManus\tradesigns-poc-live"

# Inicializar Git (se ainda nÃ£o tiver)
git init

# Criar .gitignore
# (arquivo jÃ¡ criado abaixo)

# Add e commit
git add .
git commit -m "POC Multi-Target Regression - Ready for GPU training"

# Conectar ao GitHub
git remote add origin https://github.com/frankduque/tradesigns-poc-live.git
git branch -M main
git push -u origin main
```

---

### **2ï¸âƒ£ Clonar no PC com GPU**

```bash
# No PC com GTX 1060 3GB
cd "C:\projetos"  # Ou onde preferir
git clone https://github.com/frankduque/tradesigns-poc-live.git
cd tradesigns-poc-live
```

---

### **3ï¸âƒ£ Setup ambiente Python (PC com GPU)**

```bash
# Criar ambiente virtual
python -m venv venv
.\venv\Scripts\activate

# Instalar dependÃªncias bÃ¡sicas
pip install -r requirements.txt

# Instalar LightGBM com GPU
pip install lightgbm --upgrade
```

---

### **4ï¸âƒ£ Configurar GPU (PC com GPU)**

Seguir: `docs/GPU_SETUP_GUIDE.md`

**Resumo:**
1. Verificar driver NVIDIA: `nvidia-smi`
2. Instalar CUDA 12.x (se necessÃ¡rio)
3. Testar GPU: `python test_gpu.py`

---

### **5ï¸âƒ£ Transferir dados (crÃ­tico!)**

**IMPORTANTE**: Dados nÃ£o vÃ£o pro GitHub (sÃ£o muito grandes)

**OpÃ§Ã£o A: Pen Drive / HD Externo** (recomendado)
```bash
# PC atual - copiar para pen drive
xcopy /E /I "data\" "E:\tradesigns-data\data\"

# PC com GPU - colar
xcopy /E /I "E:\tradesigns-data\data\" "C:\projetos\tradesigns-poc-live\data\"
```

**OpÃ§Ã£o B: Rede local / Google Drive**
```bash
# Compactar dados
tar -czf tradesigns_data.tar.gz data/

# Transferir por rede local ou upload
# Descompactar no PC com GPU
tar -xzf tradesigns_data.tar.gz
```

**OpÃ§Ã£o C: Re-processar dados** (mais demorado)
```bash
# No PC com GPU, reprocessar do zero
python scripts/import_histdata.py
python scripts/process_data.py
python scripts/prepare_regression_dataset.py
```

---

### **6ï¸âƒ£ Treinar com GPU!** ğŸš€

```bash
# No PC com GPU
python scripts/train_model_lightgbm_gpu.py
```

**Tempo esperado**: 5-8 minutos âš¡

---

## ğŸ“ ARQUIVOS QUE VÃƒO PRO GITHUB

### âœ… **Incluir no Git:**
```
src/                           # CÃ³digo-fonte
scripts/                       # Scripts de treino
docs/                          # DocumentaÃ§Ã£o
requirements.txt               # DependÃªncias
README.md                      # InstruÃ§Ãµes
.gitignore                     # Ignorar arquivos grandes
```

### âŒ **NÃƒO incluir (muito grandes):**
```
data/                          # Datasets (~1-2GB)
models/                        # Modelos treinados (~500MB)
logs/                          # Logs
venv/                          # Ambiente virtual
__pycache__/                   # Cache Python
*.parquet                      # Arquivos de dados
*.joblib                       # Modelos salvos
```

---

## ğŸ“„ CRIAR .gitignore

Criar arquivo `.gitignore` na raiz:

```gitignore
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
venv/
env/
ENV/

# Data files (muito grandes)
data/raw/
data/processed/
data/features/
data/results/
*.parquet
*.csv
*.zip

# Models (muito grandes)
models/
*.joblib
*.pkl
*.h5
*.pth

# Logs
logs/
*.log

# IDEs
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Jupyter
.ipynb_checkpoints/

# Temp
tmp/
temp/
```

---

## ğŸ“¦ CRIAR requirements.txt

```bash
# No PC atual, gerar requirements
pip freeze > requirements.txt
```

Ou criar manualmente:

```txt
# requirements.txt
pandas==2.2.0
numpy==1.26.3
scikit-learn==1.4.0
lightgbm==4.3.0
joblib==1.3.2
tqdm==4.66.1
pyarrow==15.0.0
```

---

## âœ… CHECKLIST DE MIGRAÃ‡ÃƒO

```
[ ] 1. Parar treino atual (Ctrl+C)
[ ] 2. Criar .gitignore
[ ] 3. Criar requirements.txt
[ ] 4. Git init + commit
[ ] 5. Criar repo no GitHub
[ ] 6. Push para GitHub
[ ] 7. Clonar no PC com GPU
[ ] 8. Setup ambiente Python
[ ] 9. Transferir dados (pen drive/rede)
[ ] 10. Configurar GPU (CUDA + drivers)
[ ] 11. Testar GPU (test_gpu.py)
[ ] 12. Treinar com GPU! ğŸš€
```

---

## ğŸ¯ RESULTADO ESPERADO

**PC atual (CPU):**
- Random Forest: 4+ horas â³

**PC com GPU (GTX 1060 3GB):**
- LightGBM GPU: 5-8 minutos âš¡
- **Speedup: ~30-50x mais rÃ¡pido!**

---

## ğŸ’¡ DICAS

1. **Dados sÃ£o o mais importante**: Priorize transferir `data/features/ml_dataset_regression.parquet`
2. **Teste pequeno primeiro**: Use subset dos dados para testar setup
3. **Monitore GPU**: Use `nvidia-smi -l 1` durante treino
4. **Salve modelos**: Depois do treino, faÃ§a backup dos modelos
5. **Documente mudanÃ§as**: Anote qualquer ajuste necessÃ¡rio

---

## ğŸ†˜ SE ALGO DER ERRADO

### GPU nÃ£o detectada
```bash
nvidia-smi  # Deve mostrar GTX 1060
nvcc --version  # Deve mostrar CUDA version
```

### LightGBM nÃ£o usa GPU
```bash
pip uninstall lightgbm
pip install lightgbm --upgrade --no-cache-dir
```

### Dados corrompidos
```bash
# Re-gerar dataset
python scripts/prepare_regression_dataset.py
```

---

**Boa sorte com a migraÃ§Ã£o! ğŸš€**

Depois me conta quanto tempo levou o treino na GPU! Aposto que vai ser <10 minutos! ğŸ®
